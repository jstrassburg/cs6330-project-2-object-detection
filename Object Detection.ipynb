{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "940d05b3",
   "metadata": {},
   "source": [
    "# Object Detection with YOLO\n",
    "\n",
    "This notebook provides a ready-to-run setup of the You Only Look Once (YOLO) v3 network for object detection. The [YOLO family of models](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Redmon_You_Only_Look_CVPR_2016_paper.html) were created by [Joseph Chet Redmon](https://pjreddie.com/).  Training these models requires large data sets like [ImageNet]() and [Microsoft COCO]() and significant compute resources, making it infeasible for most users to train their own models.  Thankfully, the researchers have released the weights of their trained models and the community has developed code that allows these models to be run with frameworks like Pytorch and Tensorflow.  This notebook uses [code](https://github.com/experiencor/keras-yolo3) released under the MIT license by [Huynh Ngoc Anh](https://github.com/experiencor) to run the pre-trained YOLO model in Keras.\n",
    "\n",
    "To use this notebook, you will need to download the YOLOv3 model weights from [https://pjreddie.com/media/files/yolov3.weights](https://pjreddie.com/media/files/yolov3.weights).  Place the `yolov3.weights` file in the same directory as this notebook.\n",
    "\n",
    "You will need to change the `input_image_path` and `output_image_path` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4888582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import yolov3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b12a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "weights_path = \"yolov3.weights\"\n",
    "\n",
    "# Supports .png, .jpg, and .jpeg files\n",
    "input_image_path = \"CHANGE_ME.jpeg\"\n",
    "output_image_path = \"CHANGE_ME_detected.jpeg\"\n",
    "\n",
    "\n",
    "net_h, net_w = 416, 416\n",
    "obj_thresh, nms_thresh = 0.5, 0.45\n",
    "anchors = [[116,90,  156,198,  373,326],  [30,61, 62,45,  59,119], [10,13,  16,30,  33,23]]\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
    "          \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
    "          \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
    "          \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
    "          \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
    "          \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
    "          \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
    "          \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
    "          \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
    "          \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a853b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the image\n",
    "image = cv2.imread(input_image_path)\n",
    "image_h, image_w, _ = image.shape\n",
    "new_image = yolov3.preprocess_input(image, net_h, net_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the yolov3 model to predict 80 classes on COCO\n",
    "model = yolov3.make_yolov3_model()\n",
    "\n",
    "# load the weights trained on COCO into the model\n",
    "weight_reader = yolov3.WeightReader(weights_path)\n",
    "weight_reader.load_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b954363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the prediction\n",
    "yolos = model.predict(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203fdfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = []\n",
    "\n",
    "for i in range(len(yolos)):\n",
    "    # decode the output of the network\n",
    "    boxes += yolov3.decode_netout(yolos[i][0], anchors[i], obj_thresh, nms_thresh, net_h, net_w)\n",
    "\n",
    "# correct the sizes of the bounding boxes\n",
    "yolov3.correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n",
    "\n",
    "# suppress non-maximal boxes\n",
    "yolov3.do_nms(boxes, nms_thresh)     \n",
    "\n",
    "# draw bounding boxes on the image using labels\n",
    "yolov3.draw_boxes(image, boxes, labels, obj_thresh) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee6e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out the resulting image with object annotations\n",
    "cv2.imwrite(output_image_path, (image).astype('uint8')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc01681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
